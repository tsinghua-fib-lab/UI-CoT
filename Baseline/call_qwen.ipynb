{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "from openai import OpenAI\n",
    "import base64    \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-mstowpepwkvabxpdxenmcyzdkzvnzolhakhcxkcjsgdkegao\", # 从https://cloud.siliconflow.cn/account/ak获取\n",
    "    base_url=\"https://api.siliconflow.cn/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_id': '601338000006',\n",
       " 'prompt': \"<image>\\nYou are provided with a street view image from a U.S. census tract. Based on the architectural style, building materials, cleanliness of the streets, and any other relevant visual indicators (such as vehicle types, landscaping quality, or visible infrastructure), evaluate the income level of the area's residents. Assign a score between 0 and 100, where 100 represents the highest income level. Additionally, estimate the predominant race of the area from the following options: \\n- White alone, not Hispanic or Latino \\n- Asian \\n- Black or African American \\n- Hispanic or Latino \\n\\nProvide your response in **exactly this format**: [income score: estimated race] \\nInclude no other information or explanation. Output must strictly follow this format.\\nFor example: `85: White alone, not Hispanic or Latino`.\",\n",
       " 'image': ['/data2/ouyangtianjian/NEW_StreetView_Images_US_CUT_merged/US_StreetView_0_to_2500_CUT/6013380000/ZDZB5BWRF2xelfl9ccaSCw&37.9231211640427&-122.366734783472&12&0.jpg']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取test set\n",
    "test_file_path = '/data3/maruolong/Train_Data/main/Data/Train_and_Test_Data/CoT_and_Original_Data/20_Paths/gc/CoT_Data/gc_CoT_test.json'\n",
    "with open(test_file_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data[0]  #一条数据样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成记录结果的文件\n",
    "answers_file = \"/data3/maruolong/Train_Data/Add_Path/Qwen2-VL-7B/train.jsonl\"\n",
    "os.makedirs(os.path.dirname(answers_file), exist_ok=True)\n",
    "ans_file = open(answers_file, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建给大模型的input\n",
    "idx = 0\n",
    "tract_id = data[idx]['sample_id']\n",
    "text = data[idx]['prompt']\n",
    "image_list = data[idx]['image']\n",
    "\n",
    "# 具体传给大模型的message\n",
    "messages=[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "            }\n",
    "        ]\n",
    "    }]\n",
    "# 图片用base64库处理后传入\n",
    "for image in image_list:\n",
    "        with open(image, \"rb\") as image_file:\n",
    "            img_url = \"data:image/jpeg;base64,\" + base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        messages[0]['content'].append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": img_url,\n",
    "                \"detail\":\"low\"\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用大模型API！\n",
    "response = client.chat.completions.create(\n",
    "            model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "            messages=messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50: White alone, not Hispanic or Latino'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description =  response.choices[0].message.content\n",
    "description=description.strip()\n",
    "description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录本次结果\n",
    "ans_file.write(json.dumps({\n",
    "                                \"tract\": tract_id[:-2],\n",
    "                                \"num\": int(tract_id[-2:]),\n",
    "                                \"predict\": description,                                   \n",
    "                                },ensure_ascii=False) + \"\\n\")\n",
    "ans_file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 25046/32052 [10:21:40<2:45:35,  1.42s/it] "
     ]
    }
   ],
   "source": [
    "\n",
    "answers_file = \"/data3/maruolong/Train_Data/main/Data/Train_and_Test_Data/CoT_and_Original_Data/20_Paths/gc/CoT_Data/gc_CoT_test.json\"\n",
    "os.makedirs(os.path.dirname(answers_file), exist_ok=True)\n",
    "ans_file = open(answers_file, \"w\")\n",
    "\n",
    "for idx in tqdm(range(len(data))):\n",
    "    tract_id = data[idx]['sample_id']\n",
    "    text = data[idx]['conversations'][0]['value']\n",
    "    ground_truth = data[idx]['conversations'][1]['value']\n",
    "    image_list = data[idx]['image']\n",
    "\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text\n",
    "                }\n",
    "            ]\n",
    "        }]\n",
    "    \n",
    "    for image in image_list:\n",
    "        try:\n",
    "            with open(image, \"rb\") as image_file:\n",
    "                base64_content = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "                if not base64_content:  # 检查base64内容是否为空\n",
    "                    print(f\"Empty base64 content for image: {image}. Skipping this image.\")\n",
    "                    continue\n",
    "                img_url = \"data:image/jpeg;base64,\" + base64_content\n",
    "            messages[0]['content'].append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": img_url,\n",
    "                    \"detail\": \"low\"\n",
    "                }\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image}: {e}. Skipping this image.\")\n",
    "            continue\n",
    "\n",
    "    if not messages[0]['content']:\n",
    "        print(f\"No valid content for sample {tract_id}. Skipping this sample.\")\n",
    "        continue\n",
    "    try:\n",
    "         response = client.chat.completions.create(\n",
    "            model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "            messages=messages,\n",
    "         )\n",
    "    except Exception as e:\n",
    "         print(\"Rate limit reached. Retrying in 5 seconds…\")\n",
    "         time.sleep(5)\n",
    "         response = client.chat.completions.create(\n",
    "            model=\"Qwen/Qwen2-VL-72B-Instruct\",\n",
    "            messages=messages,\n",
    "         ) \n",
    "\n",
    "    description =  response.choices[0].message.content\n",
    "    description=description.strip()\n",
    "\n",
    "    ans_file.write(json.dumps({\n",
    "                                \"tract\": tract_id,\n",
    "                                \"label\": ground_truth,\n",
    "                                \"predict\": description,                                   \n",
    "                                },ensure_ascii=False) + \"\\n\")\n",
    "    ans_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
